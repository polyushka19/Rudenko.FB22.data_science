{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sgWZu9eBdC0c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import urllib.request\n",
        "import os\n",
        "from datetime import datetime, date\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IovWJw0cdNqU"
      },
      "outputs": [],
      "source": [
        "Dir = 'CSV_Files'\n",
        "Url = ('https://www.star.nesdis.noaa.gov/smcd/emb/vci/VH/get_TS_admin.php?country=UKR&provinceID={''}&year1=1981&year2=2024&type=Mean')\n",
        "Indexes= {1: 24, 2: 25, 3: 5, 4: 6, 5: 27, 6: 23, 7: 26, 8: 7, 9: 11, 10: 13, 11: 14, 12: 15, 13: 16, 14: 17, 15: 18, 16: 19, 17: 21, 18: 22, 19: 8, 20: 9, 21: 10, 22: 1, 23: 3, 24: 2, 25: 4, 26: 20, 27: 12}\n",
        "\n",
        "if not os.path.exists(Dir):\n",
        "    os.makedirs(Dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqTpX_NFeT2q",
        "outputId": "9314a296-1d77-4bf7-e92c-a6442a5ace7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File for 1 created: NOAA_1_20240531120642.csv\n",
            "File for 2 created: NOAA_2_20240531120733.csv\n",
            "File for 3 created: NOAA_3_20240531120827.csv\n",
            "File for 4 created: NOAA_4_20240531120926.csv\n",
            "File for 5 created: NOAA_5_20240531121017.csv\n",
            "File for 6 created: NOAA_6_20240531121110.csv\n",
            "File for 7 created: NOAA_7_20240531121154.csv\n",
            "File for 8 created: NOAA_8_20240531121243.csv\n",
            "File for 9 created: NOAA_9_20240531121326.csv\n",
            "File for 10 created: NOAA_10_20240531121411.csv\n",
            "File for 11 created: NOAA_11_20240531121455.csv\n",
            "File for 12 created: NOAA_12_20240531121544.csv\n",
            "File for 13 created: NOAA_13_20240531121635.csv\n",
            "File for 14 created: NOAA_14_20240531121723.csv\n",
            "File for 15 created: NOAA_15_20240531121806.csv\n",
            "File for 16 created: NOAA_16_20240531121850.csv\n",
            "File for 17 created: NOAA_17_20240531121933.csv\n",
            "File for 18 created: NOAA_18_20240531122019.csv\n",
            "File for 19 created: NOAA_19_20240531122109.csv\n",
            "File for 20 created: NOAA_20_20240531122158.csv\n",
            "File for 21 created: NOAA_21_20240531122248.csv\n",
            "File for 22 created: NOAA_22_20240531122339.csv\n",
            "File for 23 created: NOAA_23_20240531122510.csv\n",
            "File for 24 created: NOAA_24_20240531122554.csv\n",
            "File for 25 created: NOAA_25_20240531122645.csv\n",
            "File for 26 created: NOAA_26_20240531122733.csv\n",
            "File for 27 created: NOAA_27_20240531122826.csv\n",
            "Success\n"
          ]
        }
      ],
      "source": [
        "for province_id in range(1, 28):\n",
        "    file_already_exists = False  # Прапорець для перевірки, чи вже є файл з ідентифікатором\n",
        "    file_name_to_check = 'NOAA_' + str(province_id) + '_'  # Ім'я файлу для перевірки\n",
        "\n",
        "    # Перевіряємо кожен файл у директорії\n",
        "    for file_name in os.listdir(Dir):\n",
        "        if file_name_to_check in file_name:\n",
        "            file_already_exists = True  # Якщо файл існує, встановлюємо прапорець\n",
        "\n",
        "    if not file_already_exists:\n",
        "        url = Url.format(Indexes[province_id])\n",
        "        wp = urllib.request.urlopen(url)\n",
        "        text = wp.read()\n",
        "        now = datetime.now()\n",
        "        date_and_time_time = now.strftime(\"%Y%m%d%H%M%S\")\n",
        "        file_name = 'NOAA_' + str(province_id) + '_' + date_and_time_time + '.csv'\n",
        "        file_path = os.path.join(Dir, file_name)\n",
        "        with open(file_path, 'wb') as out:\n",
        "            out.write(text)\n",
        "        print('File for ' + str(province_id) + ' created: ' + file_name)\n",
        "    else:\n",
        "        for file_name in os.listdir(Dir):\n",
        "            if file_name.startswith(file_name_to_check):\n",
        "                full_file_path = os.path.join(Dir, file_name)\n",
        "                with open(full_file_path, 'rb') as file:\n",
        "                    existing_text = file.read()\n",
        "                url = Url.format(Indexes[province_id])\n",
        "                wp = urllib.request.urlopen(url)\n",
        "                new_text = wp.read()\n",
        "                if existing_text != new_text:\n",
        "                    with open(full_file_path, 'wb') as file:\n",
        "                        file.write(new_text)\n",
        "                    print('File for ' + str(province_id) + ' updated.')\n",
        "                else:\n",
        "                    print('File for ' + str(province_id) + ' already exists and was not downloaded.')\n",
        "\n",
        "\n",
        "print('Success')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJRMIxH4elz6",
        "outputId": "445ffb0a-c429-4cbc-bbaa-14962823bae2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\polin\\AppData\\Local\\Temp\\ipykernel_12028\\956071423.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  dataframe = pd.concat([dataframe, df], ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully read file: NOAA_10_20240531121411.csv\n",
            "Successfully read file: NOAA_11_20240531121455.csv\n",
            "Successfully read file: NOAA_12_20240531121544.csv\n",
            "Successfully read file: NOAA_13_20240531121635.csv\n",
            "Successfully read file: NOAA_14_20240531121723.csv\n",
            "Successfully read file: NOAA_15_20240531121806.csv\n",
            "Successfully read file: NOAA_16_20240531121850.csv\n",
            "Successfully read file: NOAA_17_20240531121933.csv\n",
            "Successfully read file: NOAA_18_20240531122019.csv\n",
            "Successfully read file: NOAA_19_20240531122109.csv\n",
            "Successfully read file: NOAA_1_20240531120642.csv\n",
            "Successfully read file: NOAA_20_20240531122158.csv\n",
            "Successfully read file: NOAA_21_20240531122248.csv\n",
            "Successfully read file: NOAA_22_20240531122339.csv\n",
            "Successfully read file: NOAA_23_20240531122510.csv\n",
            "Successfully read file: NOAA_24_20240531122554.csv\n",
            "Successfully read file: NOAA_25_20240531122645.csv\n",
            "Successfully read file: NOAA_26_20240531122733.csv\n",
            "Successfully read file: NOAA_27_20240531122826.csv\n",
            "Successfully read file: NOAA_2_20240531120733.csv\n",
            "Successfully read file: NOAA_3_20240531120827.csv\n",
            "Successfully read file: NOAA_4_20240531120926.csv\n",
            "Successfully read file: NOAA_5_20240531121017.csv\n",
            "Successfully read file: NOAA_6_20240531121110.csv\n",
            "Successfully read file: NOAA_7_20240531121154.csv\n",
            "Successfully read file: NOAA_8_20240531121243.csv\n",
            "Successfully read file: NOAA_9_20240531121326.csv\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "\"['empty'] not found in axis\"",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[9], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataFrame saved to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_file_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dataframe\n\u001b[1;32m---> 30\u001b[0m result_dataframe \u001b[38;5;241m=\u001b[39m \u001b[43mread_files_to_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCSV_Files\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(result_dataframe)\n",
            "Cell \u001b[1;32mIn[9], line 26\u001b[0m, in \u001b[0;36mread_files_to_dataframe\u001b[1;34m(directory_path, output_file_path)\u001b[0m\n\u001b[0;32m     24\u001b[0m dataframe\u001b[38;5;241m.\u001b[39mdrop(dataframe\u001b[38;5;241m.\u001b[39mloc[dataframe[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVHI\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.0\u001b[39m]\u001b[38;5;241m.\u001b[39mindex, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     25\u001b[0m dataframe\u001b[38;5;241m.\u001b[39mdropna(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 26\u001b[0m dataframe \u001b[38;5;241m=\u001b[39m \u001b[43mdataframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mempty\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m dataframe\u001b[38;5;241m.\u001b[39mto_csv(output_file_path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataFrame saved to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_file_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[1;32md:\\2kurs\\ад\\data_science\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5446\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5583\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5587\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5588\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\2kurs\\ад\\data_science\\venv\\Lib\\site-packages\\pandas\\core\\generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
            "File \u001b[1;32md:\\2kurs\\ад\\data_science\\venv\\Lib\\site-packages\\pandas\\core\\generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[1;32md:\\2kurs\\ад\\data_science\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
            "\u001b[1;31mKeyError\u001b[0m: \"['empty'] not found in axis\""
          ]
        }
      ],
      "source": [
        "def read_files_to_dataframe(directory_path, output_file_path):\n",
        "    # Визначаємо назви колонок та створюємо порожій DataFrame з ними\n",
        "    headers = ['Year', 'Week', 'SMN', 'SMT', 'VCI', 'TCI', 'VHI', 'Indexes', 'empty']\n",
        "    dataframe = pd.DataFrame(columns=headers)\n",
        "\n",
        "    # Проходимо по всіх CSV-файлах у заданій директорії\n",
        "    for filename in os.listdir(directory_path):\n",
        "        if filename.endswith('.csv'):\n",
        "            file_path = os.path.join(directory_path, filename)\n",
        "            try:\n",
        "                # Зчитуємо дані з CSV-файлу, пропускаючи перші два рядки та вказуючи назви колонок\n",
        "                df = pd.read_csv(file_path, skiprows=2, names=headers[:-1])\n",
        "\n",
        "                df['Year'] = df['Year'].str.replace('<tt><pre>', '').str.replace('</pre></tt>', '')\n",
        "\n",
        "                # Визначив індекс регіону з імені файлу та додаємо його до DataFrame\n",
        "                Indexes = int(filename.split('_')[1])\n",
        "                df['Indexes'] = Indexes\n",
        "                # Об'єднуємо DataFrame кожного файлу з загальним DataFrame\n",
        "                dataframe = pd.concat([dataframe, df], ignore_index=True)\n",
        "                print(f'Successfully read file: {filename}')\n",
        "            except pd.errors.ParserError:\n",
        "                print(f'Error reading {filename}: ParserError')\n",
        "    dataframe.drop(dataframe.loc[dataframe['VHI']==-1.0].index, inplace=True)\n",
        "    dataframe.dropna(inplace=True)\n",
        "    dataframe = dataframe.drop('empty', axis=1)\n",
        "    dataframe.to_csv(output_file_path, index=False)\n",
        "    print(f'DataFrame saved to: {output_file_path}')\n",
        "    return dataframe\n",
        "result_dataframe = read_files_to_dataframe('CSV_Files', 'data.csv')\n",
        "print(result_dataframe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6p5_YADes1m"
      },
      "source": [
        "Ряд VHI для області за вказаний рік, пошук екстремумів (min та max);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7F_L8Lleex3v",
        "outputId": "7436218f-8dd7-490e-d0bd-c2295c21d0cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Min VHI для області з індексом 1 у 1982: 19.92, Max VHI для області з індексом 1 у 1982: 59.42\n",
            "Min VHI для області з індексом 2 у 1982: 23.55, Max VHI для області з індексом 2 у 1982: 53.88\n",
            "Min VHI для області з індексом 3 у 1982: 27.91, Max VHI для області з індексом 3 у 1982: 66.07\n",
            "Min VHI для області з індексом 4 у 1982: 28.39, Max VHI для області з індексом 4 у 1982: 74.19\n",
            "Min VHI для області з індексом 5 у 1982: 29.69, Max VHI для області з індексом 5 у 1982: 59.19\n",
            "Min VHI для області з індексом 6 у 1982: 29.13, Max VHI для області з індексом 6 у 1982: 54.44\n",
            "Min VHI для області з індексом 7 у 1982: 24.18, Max VHI для області з індексом 7 у 1982: 63.14\n",
            "Min VHI для області з індексом 8 у 1982: 24.64, Max VHI для області з індексом 8 у 1982: 53.0\n",
            "Min VHI для області з індексом 9 у 1982: 31.48, Max VHI для області з індексом 9 у 1982: 63.72\n",
            "Min VHI для області з індексом 10 у 1982: 25.96, Max VHI для області з індексом 10 у 1982: 64.92\n",
            "Min VHI для області з індексом 11 у 1982: 28.66, Max VHI для області з індексом 11 у 1982: 84.29\n",
            "Min VHI для області з індексом 12 у 1982: 22.23, Max VHI для області з індексом 12 у 1982: 53.26\n",
            "Min VHI для області з індексом 13 у 1982: 26.93, Max VHI для області з індексом 13 у 1982: 65.64\n",
            "Min VHI для області з індексом 14 у 1982: 21.33, Max VHI для області з індексом 14 у 1982: 64.29\n",
            "Min VHI для області з індексом 15 у 1982: 30.48, Max VHI для області з індексом 15 у 1982: 65.2\n",
            "Min VHI для області з індексом 16 у 1982: 26.98, Max VHI для області з індексом 16 у 1982: 55.58\n",
            "Min VHI для області з індексом 17 у 1982: 29.46, Max VHI для області з індексом 17 у 1982: 68.51\n",
            "Min VHI для області з індексом 18 у 1982: 26.95, Max VHI для області з індексом 18 у 1982: 48.77\n",
            "Min VHI для області з індексом 19 у 1982: 28.77, Max VHI для області з індексом 19 у 1982: 73.75\n",
            "Min VHI для області з індексом 20 у 1982: 26.65, Max VHI для області з індексом 20 у 1982: 62.22\n",
            "Min VHI для області з індексом 21 у 1982: 22.82, Max VHI для області з індексом 21 у 1982: 51.83\n",
            "Min VHI для області з індексом 22 у 1982: 23.83, Max VHI для області з індексом 22 у 1982: 64.58\n",
            "Min VHI для області з індексом 23 у 1982: 22.44, Max VHI для області з індексом 23 у 1982: 50.09\n",
            "Min VHI для області з індексом 24 у 1982: 30.98, Max VHI для області з індексом 24 у 1982: 64.27\n",
            "Min VHI для області з індексом 25 у 1982: 30.43, Max VHI для області з індексом 25 у 1982: 64.88\n",
            "Min VHI для області з індексом 26 у 1982: 24.94, Max VHI для області з індексом 26 у 1982: 47.0\n",
            "Min VHI для області з індексом 27 у 1982: 23.95, Max VHI для області з індексом 27 у 1982: 61.65\n",
            "Min VHI для області з індексом 28 у 1982: nan, Max VHI для області з індексом 28 у 1982: nan\n"
          ]
        }
      ],
      "source": [
        "def procedure_1(dataframe, Indexes, year):\n",
        "    # Визначає підфрейм за значеннями стовпців Року та Регіону\n",
        "    region_data = dataframe[(dataframe['Indexes'] == Indexes) & (dataframe['Year'] == year)]\n",
        "    min_vhi_value = region_data['VHI'].min()\n",
        "    max_vhi_value = region_data['VHI'].max()\n",
        "    return min_vhi_value, max_vhi_value\n",
        "\n",
        "df = pd.read_csv('data.csv')\n",
        "\n",
        "for i in range(1, 29):\n",
        "    min_vhi, max_vhi = procedure_1(df, Indexes=i, year=1982)\n",
        "    print(f\"Min VHI для області з індексом {i} у 1982: {min_vhi}, Max VHI для області з індексом {i} у 1982: {max_vhi}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzwsxnfzg8Wi"
      },
      "source": [
        "Ряд VHI за вказаний діапазон років для вказаних областей; виявити роки, протягом яких екстремальні посухи торкнулися більше вказаного відсотка областей по Україні (20% областей - 5 областей з 25);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ls_bzIn0g-9E",
        "outputId": "5970ec18-6d4f-4e52-d8e0-c0343a16b245"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For province 3 extreme drought is in years: 1982.0, 1983.0, 1984.0\n",
            "For province 7 extreme drought is in years: 1982.0, 1983.0, 1984.0\n",
            "For province 12 extreme drought is in years: 1982.0, 1983.0, 1984.0\n",
            "For province 18 extreme drought is in years: 1982.0, 1983.0, 1984.0\n",
            "For province 20 extreme drought is in years: 1982.0, 1983.0, 1984.0\n"
          ]
        }
      ],
      "source": [
        "def find_years_with_extreme_drought(df, threshold_percentage, selected_years, selected_provinces):\n",
        "    years_with_extreme_drought = []\n",
        "\n",
        "    # Рахуємо кількість областей з екстремальною посухою для кожного року\n",
        "    for year in df['Year'].unique():\n",
        "        if year not in selected_years:\n",
        "            continue\n",
        "        provinces_with_drought = df[(df['Year'] == year) & (df['VHI'] <= 50)]['Indexes'].unique()\n",
        "        percentage = len(provinces_with_drought) / len(selected_provinces) * 100\n",
        "        if percentage >= threshold_percentage:\n",
        "            years_with_extreme_drought.append(year)\n",
        "\n",
        "    return years_with_extreme_drought\n",
        "\n",
        "def procedure_2(df, threshold_percentage, selected_years, selected_provinces):\n",
        "    for province_n in selected_provinces:\n",
        "        years_with_extreme_drought = find_years_with_extreme_drought(df[df['Indexes'] == province_n], threshold_percentage, selected_years, selected_provinces)\n",
        "        if years_with_extreme_drought:\n",
        "            print(f'For province {province_n} extreme drought is in years: {\", \".join(map(str, years_with_extreme_drought))}')\n",
        "\n",
        "# Задайте відсоток порогу, роки та області\n",
        "threshold_percentage = 20\n",
        "selected_years = [1982, 1983, 1984]  # Приклад обраних років\n",
        "selected_provinces = [3, 7, 12, 18, 20]  # Приклад обраних областей\n",
        "\n",
        "# Виклик функції procedure_2 з заданими параметрами\n",
        "procedure_2(df, threshold_percentage, selected_years, selected_provinces)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MdIxLPehGkq",
        "outputId": "09a7d6ce-b604-4d4e-9156-8a610b8accf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For the province 3 extreme drought is in:\n",
            "Years: 1982.0 1983.0 1984.0 1985.0 1986.0 1987.0 1988.0 1989.0 1990.0 1991.0 1992.0 1993.0 1994.0 1995.0 1996.0 1997.0 1998.0 1999.0 2000.0 2001.0 2002.0 2003.0 2004.0 2005.0 2006.0 2007.0 2008.0 2009.0 2010.0 2011.0 2012.0 2013.0 2014.0 2015.0 2016.0 2017.0 2018.0 2019.0 2020.0 2021.0 2022.0 2023.0 2024.0\n"
          ]
        }
      ],
      "source": [
        "def procedure_2(df, province_n):\n",
        "    df_drought = df[(df[\"Indexes\"] == province_n) & (df.VHI <= 50)]\n",
        "    list_from_ds = list(df_drought.Year)\n",
        "    years = set()  # Використовуємо множину для унікальних років\n",
        "    [years.add(str(item)) for item in list_from_ds]  # Додаємо рік до множини\n",
        "    sorted_years = sorted(years, key=lambda x: float(x))  # Сортуємо роки за зростанням\n",
        "    print('For the province ' + str(province_n) + ' extreme drought is in:')\n",
        "    print('Years: ' + ' '.join(sorted_years))\n",
        "\n",
        "procedure_2(df, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D--7QJxehOX3"
      },
      "source": [
        "Аналогічно для помірних посух"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tf0jjjQGhRKi",
        "outputId": "c38180bb-5b4e-4c08-97ca-1cbc314785e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For province 3 moderate drought is in years: 1982.0, 1983.0, 2002.0\n",
            "For province 7 moderate drought is in years: 1982.0, 1983.0, 2002.0\n",
            "For province 12 moderate drought is in years: 1982.0, 1983.0\n",
            "For province 18 moderate drought is in years: 1982.0, 1983.0\n",
            "For province 20 moderate drought is in years: 1982.0, 1983.0, 2002.0\n"
          ]
        }
      ],
      "source": [
        "def find_years_with_moderate_drought(df, threshold_percentage, selected_years, selected_provinces):\n",
        "    years_with_moderate_drought = []\n",
        "\n",
        "    # Рахуємо кількість областей з помірною посухою для кожного року\n",
        "    for year in df['Year'].unique():\n",
        "        if year not in selected_years:\n",
        "            continue\n",
        "        provinces_with_drought = df[(df['Year'] == year) & (df['VHI'] <= 35) & (df['VHI'] > 15)]['Indexes'].unique()\n",
        "        percentage = len(provinces_with_drought) / len(selected_provinces) * 100\n",
        "        if percentage >= threshold_percentage:\n",
        "            years_with_moderate_drought.append(year)\n",
        "\n",
        "    return years_with_moderate_drought\n",
        "\n",
        "def procedure_moderate_drought(df, threshold_percentage, selected_years, selected_provinces):\n",
        "    for province_n in selected_provinces:\n",
        "        years_with_moderate_drought = find_years_with_moderate_drought(df[df['Indexes'] == province_n], threshold_percentage, selected_years, selected_provinces)\n",
        "        if years_with_moderate_drought:\n",
        "            print(f'For province {province_n} moderate drought is in years: {\", \".join(map(str, years_with_moderate_drought))}')\n",
        "\n",
        "# Задайте відсоток порогу, роки та області\n",
        "threshold_percentage = 20\n",
        "selected_years = [1982, 1983, 2002]  # Приклад обраних років\n",
        "selected_provinces = [3, 7, 12, 18, 20]  # Приклад обраних областей\n",
        "\n",
        "# Виклик функції procedure_moderate_drought з заданими параметрами\n",
        "procedure_moderate_drought(df, threshold_percentage, selected_years, selected_provinces)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tjL1Y2ohZ-T",
        "outputId": "292ad923-8ee3-49aa-e32a-d22409328e33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For the province 3 moderate drought is in:\n",
            "Years: 1982.0 1983.0 1984.0 1985.0 1986.0 1988.0 1989.0 1990.0 1992.0 1993.0 1994.0 1995.0 1996.0 1997.0 1999.0 2000.0 2001.0 2002.0 2003.0 2005.0 2006.0 2007.0 2008.0 2010.0 2011.0 2012.0 2013.0 2014.0 2015.0 2016.0 2017.0 2018.0 2019.0 2020.0 2021.0 2023.0\n"
          ]
        }
      ],
      "source": [
        "def procedure_3(df, province_n):\n",
        "    df_drought = df[(df[\"Indexes\"] == province_n) & (df.VHI <= 35) & (df.VHI > 15)]\n",
        "    list_from_ds = list(df_drought.Year)\n",
        "    years = []\n",
        "    [years.append(str(item)) for item in list_from_ds if str(item) not in years]  # Перетворення на рядок\n",
        "    print('For the province ' + str(province_n) + ' moderate drought is in:')\n",
        "    print('Years: ' + ' '.join(years))\n",
        "\n",
        "procedure_3(df, 3)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
